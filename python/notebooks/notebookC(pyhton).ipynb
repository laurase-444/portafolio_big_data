{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "635f51a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: string, value: string]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = pyspark.SparkConf().setAppName('appName').setMaster('local[4]').set('spark.jars.packages', 'graphframes:graphframes:0.8.0-spark2.4-s_2.11')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)\n",
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff49d967",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJERCICIO 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7beef95a",
   "metadata": {},
   "source": [
    "Leer por separado cada uno de ellos (sin cachear), tratando de que Spark infiera el tipo de dato de cada columna, y unirlos en un solo DF que tampoco debe ser cacheada todavía, ya que en el siguiente paso aún realizaremos otro pre-procesamiento.\n",
    "Los cuatro contienen las mismas columnas por lo que no habrá problemas para utilizar la operación union encadenada tres veces para crear el DF final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2ee84b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "# LÍNEA EVALUABLE, NO RENOMBRAR LAS VARIABLES\n",
    "tripsQ1 = (spark.read.format(\"csv\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "        .option(\"inferSchema\", \"true\")\\\n",
    "        .load(\"C:/Users/laura.serrano/Desktop/Bike Share Toronto Ridership_Q1 2018.csv\"))\n",
    "tripsQ2 = (spark.read.format(\"csv\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "        .option(\"inferSchema\", \"true\")\\\n",
    "        .load('C:/Users/laura.serrano/Desktop/Bike Share Toronto Ridership_Q2 2018.csv'))\n",
    "tripsQ3 = (spark.read.format(\"csv\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "        .option(\"inferSchema\", \"true\")\\\n",
    "        .load('C:/Users/laura.serrano/Desktop/Bike Share Toronto Ridership_Q3 2018.csv'))\n",
    "tripsQ4 = (spark.read.format(\"csv\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "        .option(\"inferSchema\", \"true\")\\\n",
    "        .load('C:/Users/laura.serrano/Desktop/Bike Share Toronto Ridership_Q4 2018.csv'))\n",
    "tripsTorontoRawDF = tripsQ1.union(tripsQ2).union(tripsQ3).union(tripsQ4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7640ec2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+---------------+---------------+--------------------+--------------+-------------+--------------------+-------------+\n",
      "|trip_id|trip_duration_seconds|from_station_id|trip_start_time|   from_station_name|trip_stop_time|to_station_id|     to_station_name|    user_type|\n",
      "+-------+---------------------+---------------+---------------+--------------------+--------------+-------------+--------------------+-------------+\n",
      "|2383648|                  393|           7018|  1/1/2018 0:47|Bremner Blvd / Re...| 1/1/2018 0:54|         7176|Bathurst St / For...|Annual Member|\n",
      "|2383649|                  625|           7184|  1/1/2018 0:52|Ossington Ave / C...| 1/1/2018 1:03|         7191|Central Tech  (Ha...|Annual Member|\n",
      "|2383650|                  233|           7235|  1/1/2018 0:55|Bay St / College ...| 1/1/2018 0:59|         7021|  Bay St / Albert St|Annual Member|\n",
      "|2383651|                 1138|           7202|  1/1/2018 0:57|Queen St W / York...| 1/1/2018 1:16|         7020|Phoebe St / Spadi...|Annual Member|\n",
      "|2383652|                  703|           7004|  1/1/2018 1:00|University Ave / ...| 1/1/2018 1:12|         7060|Princess St / Ade...|Annual Member|\n",
      "|2383653|                 1026|           7078|  1/1/2018 1:07|College St / Majo...| 1/1/2018 1:24|         7130|Pears Av / Avenue Rd|Annual Member|\n",
      "|2383654|                  274|           7021|  1/1/2018 1:33|  Bay St / Albert St| 1/1/2018 1:38|         7033|       Union Station|Annual Member|\n",
      "|2383655|                  764|           7046|  1/1/2018 1:34|Niagara St / Rich...| 1/1/2018 1:47|         7275|Queen St W / Jame...|Annual Member|\n",
      "|2383657|                  237|           7044|  1/1/2018 1:37|Church St / Alexa...| 1/1/2018 1:41|         7028|Gould St / Mutual St|Annual Member|\n",
      "|2383658|                  180|           7198|  1/1/2018 1:38|Queen St W / Cowa...| 1/1/2018 1:41|         7193|Queen St W / Glad...|Annual Member|\n",
      "|2383659|                  957|           7061|  1/1/2018 1:39|Dalton Rd / Bloor...| 1/1/2018 1:55|         7002|St. George St / B...|Annual Member|\n",
      "|2383660|                  898|           7177|  1/1/2018 1:39|East Liberty St /...| 1/1/2018 1:54|         7206|Claremont St / Du...|Annual Member|\n",
      "|2383661|                 1529|           7107|  1/1/2018 1:49|Cherry St / Disti...| 1/1/2018 2:14|         7211|Fort York Blvd / ...|Annual Member|\n",
      "|2383662|                  253|           7078|  1/1/2018 1:57|College St / Majo...| 1/1/2018 2:01|         7195|Ulster St / Bathu...|Annual Member|\n",
      "|2383663|                  348|           7095|  1/1/2018 2:06|Danforth Ave / El...| 1/1/2018 2:11|         7117|Castle Frank Station|Annual Member|\n",
      "|2383664|                  797|           7160|  1/1/2018 2:25|King St W / Tecum...| 1/1/2018 2:38|         7136|Queen St W / Clos...|Casual Member|\n",
      "|2383665|                  352|           7140|  1/1/2018 2:29|Macpherson Ave / ...| 1/1/2018 2:35|         7003|Madison Ave / Blo...|Annual Member|\n",
      "|2383666|                  382|           7149|  1/1/2018 2:30|Yarmouth Rd / Chr...| 1/1/2018 2:36|         7153|Bloor St W / Chri...|Annual Member|\n",
      "|2383667|                  433|           7111|  1/1/2018 2:45|King St W / Douro St| 1/1/2018 2:52|         7176|Bathurst St / For...|Annual Member|\n",
      "|2383668|                  589|           7067|  1/1/2018 2:53|Yonge St / Harbou...| 1/1/2018 3:03|         7259|Lower Spadina Ave...|Annual Member|\n",
      "+-------+---------------------+---------------+---------------+--------------------+--------------+-------------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tripsTorontoRawDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56114600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "assert(tripsTorontoRawDF.count() == 1922955)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "838127ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJERCICIO 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da5ac8e",
   "metadata": {},
   "source": [
    "Las columnas trip_start_time y trip_stop_time son en realidad instantes de tiempo que Spark debería procesar como timestamp. Reemplaza ambas columnas por su versión convertida a timestamp, utilizando withColumn y donde el nuevo valor de la columna viene dado por el siguiente código:\n",
    "  F.from_unixtime(F.unix_timestamp('nombreColumna', 'MM/dd/yyyy HH:mm')).cast(\"timestamp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78e189d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tripsTorontoDF = tripsTorontoRawDF.withColumn(\"trip_start_time\",\\\n",
    "                                    (F.from_unixtime(F.unix_timestamp('trip_start_time', 'MM/dd/yyyy HH:mm'))).cast(\"timestamp\"))\\\n",
    "                                .withColumn(\"trip_stop_time\",\\\n",
    "                                    (F.from_unixtime(F.unix_timestamp('trip_stop_time', 'MM/dd/yyyy HH:mm'))).cast(\"timestamp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "555c8ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+---------------+-------------------+--------------------+-------------------+-------------+--------------------+-------------+\n",
      "|trip_id|trip_duration_seconds|from_station_id|    trip_start_time|   from_station_name|     trip_stop_time|to_station_id|     to_station_name|    user_type|\n",
      "+-------+---------------------+---------------+-------------------+--------------------+-------------------+-------------+--------------------+-------------+\n",
      "|2383648|                  393|           7018|2018-01-01 00:47:00|Bremner Blvd / Re...|2018-01-01 00:54:00|         7176|Bathurst St / For...|Annual Member|\n",
      "|2383649|                  625|           7184|2018-01-01 00:52:00|Ossington Ave / C...|2018-01-01 01:03:00|         7191|Central Tech  (Ha...|Annual Member|\n",
      "|2383650|                  233|           7235|2018-01-01 00:55:00|Bay St / College ...|2018-01-01 00:59:00|         7021|  Bay St / Albert St|Annual Member|\n",
      "|2383651|                 1138|           7202|2018-01-01 00:57:00|Queen St W / York...|2018-01-01 01:16:00|         7020|Phoebe St / Spadi...|Annual Member|\n",
      "|2383652|                  703|           7004|2018-01-01 01:00:00|University Ave / ...|2018-01-01 01:12:00|         7060|Princess St / Ade...|Annual Member|\n",
      "|2383653|                 1026|           7078|2018-01-01 01:07:00|College St / Majo...|2018-01-01 01:24:00|         7130|Pears Av / Avenue Rd|Annual Member|\n",
      "|2383654|                  274|           7021|2018-01-01 01:33:00|  Bay St / Albert St|2018-01-01 01:38:00|         7033|       Union Station|Annual Member|\n",
      "|2383655|                  764|           7046|2018-01-01 01:34:00|Niagara St / Rich...|2018-01-01 01:47:00|         7275|Queen St W / Jame...|Annual Member|\n",
      "|2383657|                  237|           7044|2018-01-01 01:37:00|Church St / Alexa...|2018-01-01 01:41:00|         7028|Gould St / Mutual St|Annual Member|\n",
      "|2383658|                  180|           7198|2018-01-01 01:38:00|Queen St W / Cowa...|2018-01-01 01:41:00|         7193|Queen St W / Glad...|Annual Member|\n",
      "|2383659|                  957|           7061|2018-01-01 01:39:00|Dalton Rd / Bloor...|2018-01-01 01:55:00|         7002|St. George St / B...|Annual Member|\n",
      "|2383660|                  898|           7177|2018-01-01 01:39:00|East Liberty St /...|2018-01-01 01:54:00|         7206|Claremont St / Du...|Annual Member|\n",
      "|2383661|                 1529|           7107|2018-01-01 01:49:00|Cherry St / Disti...|2018-01-01 02:14:00|         7211|Fort York Blvd / ...|Annual Member|\n",
      "|2383662|                  253|           7078|2018-01-01 01:57:00|College St / Majo...|2018-01-01 02:01:00|         7195|Ulster St / Bathu...|Annual Member|\n",
      "|2383663|                  348|           7095|2018-01-01 02:06:00|Danforth Ave / El...|2018-01-01 02:11:00|         7117|Castle Frank Station|Annual Member|\n",
      "|2383664|                  797|           7160|2018-01-01 02:25:00|King St W / Tecum...|2018-01-01 02:38:00|         7136|Queen St W / Clos...|Casual Member|\n",
      "|2383665|                  352|           7140|2018-01-01 02:29:00|Macpherson Ave / ...|2018-01-01 02:35:00|         7003|Madison Ave / Blo...|Annual Member|\n",
      "|2383666|                  382|           7149|2018-01-01 02:30:00|Yarmouth Rd / Chr...|2018-01-01 02:36:00|         7153|Bloor St W / Chri...|Annual Member|\n",
      "|2383667|                  433|           7111|2018-01-01 02:45:00|King St W / Douro St|2018-01-01 02:52:00|         7176|Bathurst St / For...|Annual Member|\n",
      "|2383668|                  589|           7067|2018-01-01 02:53:00|Yonge St / Harbou...|2018-01-01 03:03:00|         7259|Lower Spadina Ave...|Annual Member|\n",
      "+-------+---------------------+---------------+-------------------+--------------------+-------------------+-------------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tripsTorontoDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bd0e8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "typesDict = dict(tripsTorontoDF.dtypes)\n",
    "assert(typesDict[\"trip_start_time\"] == \"timestamp\") \n",
    "assert(typesDict[\"trip_stop_time\"] == \"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6055234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJERCICIO 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bcf2c0",
   "metadata": {},
   "source": [
    "Partiendo de tripsTorontoDF, realizar las siguientes transformaciones encadenadas en este orden para crear un nuevo DF:\n",
    "\n",
    "Primero, debemos quedarnos solamente con las filas donde trip_start_time no sea null.\n",
    "Sobre el DF resultado de lo anterior, añadir una columna adicional Mes y con el mes representado en trip_start_time. Dicha columna será de tipo entero y se puede obtener usando withColumn con la función F.month(\"colName\"), que recibe un nombre de columna y devuelve un objeto columna de enteros que van de 1 a 12.\n",
    "Encadenar esta transformación con otra en la que la columna Mes sea reemplazada por su traducción a cadena de caracteres de 3 letras, siendo la correspondencia 1: Ene, 2: Feb, 3: Mar, 4: Abr, 5: May, 6: Jun, 7: Jul, 8: Ago, 9: Sep, 10: Oct, 11: Nov, 12: Dic.\n",
    "Finalmente, añadir una nueva columna Hora que contenga la hora de inicio del viaje, aplicando withColumn con la función F.hour(\"colName\") que recibe un nombre de columna y recibe un objeto columna de enteros de 0 a 23.\n",
    "El DF resultante de todas estas transformaciones debe guardarse en la variable tripsTorontoTimesDF, que por tanto tendrá 2 columnas más que el DF original tripsTorontoDF, y que debe quedar cacheado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f129268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "tripsTorontoTimesDF = (tripsTorontoDF.select('*').where(F.col(\"trip_start_time\").isNotNull())\\\n",
    "                                    .withColumn(\"Mes\", F.month(\"trip_start_time\").cast(IntegerType()))\\\n",
    "                                    .withColumn(\"Mes\", F.when((F.col(\"Mes\") == 1), \"Ene\")\\\n",
    "                                               .when((F.col(\"Mes\") == 2), \"Feb\")\\\n",
    "                                               .when((F.col(\"Mes\") == 3), \"Mar\")\\\n",
    "                                               .when((F.col(\"Mes\") == 4), \"Abr\")\\\n",
    "                                               .when((F.col(\"Mes\") == 5), \"May\")\\\n",
    "                                               .when((F.col(\"Mes\") == 6), \"Jun\")\\\n",
    "                                               .when((F.col(\"Mes\") == 7), \"Jul\")\\\n",
    "                                               .when((F.col(\"Mes\") == 8), \"Ago\")\\\n",
    "                                               .when((F.col(\"Mes\") == 9), \"Sep\")\\\n",
    "                                               .when((F.col(\"Mes\") == 10), \"Oct\")\\\n",
    "                                               .when((F.col(\"Mes\") == 11), \"Nov\")\\\n",
    "                                               .when((F.col(\"Mes\") == 12), \"Dic\"))\\\n",
    "                                     .withColumn(\"Hora\", F.hour(\"trip_start_time\")))\\\n",
    ".cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57acad7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- trip_id: integer (nullable = true)\n",
      " |-- trip_duration_seconds: integer (nullable = true)\n",
      " |-- from_station_id: integer (nullable = true)\n",
      " |-- trip_start_time: timestamp (nullable = true)\n",
      " |-- from_station_name: string (nullable = true)\n",
      " |-- trip_stop_time: timestamp (nullable = true)\n",
      " |-- to_station_id: integer (nullable = true)\n",
      " |-- to_station_name: string (nullable = true)\n",
      " |-- user_type: string (nullable = true)\n",
      " |-- Mes: string (nullable = true)\n",
      " |-- Hora: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tripsTorontoTimesDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06a3529d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+---------------+-------------------+--------------------+-------------------+-------------+--------------------+-------------+---+----+\n",
      "|trip_id|trip_duration_seconds|from_station_id|    trip_start_time|   from_station_name|     trip_stop_time|to_station_id|     to_station_name|    user_type|Mes|Hora|\n",
      "+-------+---------------------+---------------+-------------------+--------------------+-------------------+-------------+--------------------+-------------+---+----+\n",
      "|2383648|                  393|           7018|2018-01-01 00:47:00|Bremner Blvd / Re...|2018-01-01 00:54:00|         7176|Bathurst St / For...|Annual Member|Ene|   0|\n",
      "|2383649|                  625|           7184|2018-01-01 00:52:00|Ossington Ave / C...|2018-01-01 01:03:00|         7191|Central Tech  (Ha...|Annual Member|Ene|   0|\n",
      "|2383650|                  233|           7235|2018-01-01 00:55:00|Bay St / College ...|2018-01-01 00:59:00|         7021|  Bay St / Albert St|Annual Member|Ene|   0|\n",
      "|2383651|                 1138|           7202|2018-01-01 00:57:00|Queen St W / York...|2018-01-01 01:16:00|         7020|Phoebe St / Spadi...|Annual Member|Ene|   0|\n",
      "|2383652|                  703|           7004|2018-01-01 01:00:00|University Ave / ...|2018-01-01 01:12:00|         7060|Princess St / Ade...|Annual Member|Ene|   1|\n",
      "|2383653|                 1026|           7078|2018-01-01 01:07:00|College St / Majo...|2018-01-01 01:24:00|         7130|Pears Av / Avenue Rd|Annual Member|Ene|   1|\n",
      "|2383654|                  274|           7021|2018-01-01 01:33:00|  Bay St / Albert St|2018-01-01 01:38:00|         7033|       Union Station|Annual Member|Ene|   1|\n",
      "|2383655|                  764|           7046|2018-01-01 01:34:00|Niagara St / Rich...|2018-01-01 01:47:00|         7275|Queen St W / Jame...|Annual Member|Ene|   1|\n",
      "|2383657|                  237|           7044|2018-01-01 01:37:00|Church St / Alexa...|2018-01-01 01:41:00|         7028|Gould St / Mutual St|Annual Member|Ene|   1|\n",
      "|2383658|                  180|           7198|2018-01-01 01:38:00|Queen St W / Cowa...|2018-01-01 01:41:00|         7193|Queen St W / Glad...|Annual Member|Ene|   1|\n",
      "|2383659|                  957|           7061|2018-01-01 01:39:00|Dalton Rd / Bloor...|2018-01-01 01:55:00|         7002|St. George St / B...|Annual Member|Ene|   1|\n",
      "|2383660|                  898|           7177|2018-01-01 01:39:00|East Liberty St /...|2018-01-01 01:54:00|         7206|Claremont St / Du...|Annual Member|Ene|   1|\n",
      "|2383661|                 1529|           7107|2018-01-01 01:49:00|Cherry St / Disti...|2018-01-01 02:14:00|         7211|Fort York Blvd / ...|Annual Member|Ene|   1|\n",
      "|2383662|                  253|           7078|2018-01-01 01:57:00|College St / Majo...|2018-01-01 02:01:00|         7195|Ulster St / Bathu...|Annual Member|Ene|   1|\n",
      "|2383663|                  348|           7095|2018-01-01 02:06:00|Danforth Ave / El...|2018-01-01 02:11:00|         7117|Castle Frank Station|Annual Member|Ene|   2|\n",
      "|2383664|                  797|           7160|2018-01-01 02:25:00|King St W / Tecum...|2018-01-01 02:38:00|         7136|Queen St W / Clos...|Casual Member|Ene|   2|\n",
      "|2383665|                  352|           7140|2018-01-01 02:29:00|Macpherson Ave / ...|2018-01-01 02:35:00|         7003|Madison Ave / Blo...|Annual Member|Ene|   2|\n",
      "|2383666|                  382|           7149|2018-01-01 02:30:00|Yarmouth Rd / Chr...|2018-01-01 02:36:00|         7153|Bloor St W / Chri...|Annual Member|Ene|   2|\n",
      "|2383667|                  433|           7111|2018-01-01 02:45:00|King St W / Douro St|2018-01-01 02:52:00|         7176|Bathurst St / For...|Annual Member|Ene|   2|\n",
      "|2383668|                  589|           7067|2018-01-01 02:53:00|Yonge St / Harbou...|2018-01-01 03:03:00|         7259|Lower Spadina Ave...|Annual Member|Ene|   2|\n",
      "+-------+---------------------+---------------+-------------------+--------------------+-------------------+-------------+--------------------+-------------+---+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tripsTorontoTimesDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0daae0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tripsPerMonth = tripsTorontoTimesDF.groupBy(\"Mes\").count().sort(\"Mes\").collect()\n",
    "assert(tripsPerMonth[0][\"count\"] == 94783)\n",
    "assert(tripsPerMonth[1][\"count\"] == 281219)\n",
    "assert(tripsPerMonth[2][\"count\"] == 83324)\n",
    "assert(tripsPerMonth[3][\"count\"] == 43859)\n",
    "assert(tripsPerMonth[4][\"count\"] == 49731)\n",
    "assert(tripsPerMonth[5][\"count\"] == 286316)\n",
    "assert(tripsPerMonth[6][\"count\"] == 250837)\n",
    "assert((tripsPerMonth[7][\"count\"] == 84959) | (tripsPerMonth[7][\"count\"] == 84969))\n",
    "assert(tripsPerMonth[8][\"count\"] == 212750)\n",
    "assert(tripsPerMonth[9][\"count\"] == 104287)\n",
    "assert(tripsPerMonth[10][\"count\"] == 175879)\n",
    "assert(tripsPerMonth[11][\"count\"] == 255001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79419052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJERCICIO 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9825f5",
   "metadata": {},
   "source": [
    "Partiendo de tripsTorontoTimesDF, crear un nuevo DataFrame con tantas filas como horas tiene el día, y tantas columnas como meses del año de manera que cada celda indique el número de viajes que comenzaron a esa hora en ese mes del año. Guardar el resultado en la variable tripsPerMonthAndHourDF, cuyas filas deben quedar ordenadas en base a la hora (de 0 a 23), y cuyas columnas deben estar también ordenadas desde \"Ene\" a \"Dic\", con \"Hora\" como primera columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a87551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LÍNEA EVALUABLE, NO RENOMBRAR VARIABLES\n",
    "tripsPerMonthAndHourDF =  (tripsTorontoTimesDF.groupBy(\"Hora\").pivot(\"Mes\").count())\\\n",
    ".select(\"Hora\", \"Ene\", \"Feb\", \"Mar\", \"Abr\", \"May\", \"Jun\", \"Jul\", \"Ago\", \"Sep\", \"Oct\", \"Nov\", \"Dic\")\\\n",
    ".orderBy(\"Hora\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e42b031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+----+\n",
      "|Hora| Ene| Feb|  Mar|  Abr|  May|  Jun|  Jul|  Ago|  Sep|  Oct|  Nov| Dic|\n",
      "+----+----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+----+\n",
      "|   0| 425| 412|  689|  770| 1913| 2859| 3418| 2912| 2623| 1419|  888| 782|\n",
      "|   1| 266| 308|  434|  493| 1180| 1725| 1991| 1831| 1689|  943|  637| 525|\n",
      "|   2| 201| 183|  308|  374|  804| 1274| 1356| 1360| 1344|  684|  442| 417|\n",
      "|   3|  91| 101|  156|  130|  361|  587|  646|  595|  632|  245|  211| 164|\n",
      "|   4|  49|  56|  133|  114|  227|  463|  494|  504|  467|  264|  253| 187|\n",
      "|   5| 198| 226|  348|  381|  627|  877| 1121| 1110| 1032|  860|  569| 373|\n",
      "|   6| 603| 668|  995| 1092| 2043| 2802| 3232| 3088| 2800| 2373| 1745|1082|\n",
      "|   7|1742|2011| 3303| 3436| 6626| 8209| 8978| 8146| 8130| 6217| 4286|2914|\n",
      "|   8|5001|5199| 8682| 9825|17855|20602|23931|22475|21216|17825|11720|8293|\n",
      "|   9|3728|3769| 6497| 6790|12063|14044|16089|14978|14710|12381| 8314|6287|\n",
      "|  10|1975|2017| 3557| 3624| 7830| 8641|10195|10306| 9873| 6935| 4100|3634|\n",
      "|  11|1873|1893| 3747| 3865| 9278|10121|11823|12570|11549| 7437| 4444|3900|\n",
      "|  12|2259|2386| 4548| 4761|11427|12701|14796|15539|14362| 9308| 5445|4696|\n",
      "|  13|2117|2334| 4379| 4878|12117|13189|15492|16393|14755| 9089| 5296|4908|\n",
      "|  14|2002|2269| 4271| 4735|11909|13186|14915|15775|14261| 8573| 4910|4786|\n",
      "|  15|2483|2855| 4933| 5690|13518|14495|16429|16923|16075| 9899| 5835|5362|\n",
      "|  16|3936|4482| 7333| 8475|18306|19759|22815|22772|21378|14895| 8682|7146|\n",
      "|  17|4981|6320|10064|11456|25144|28216|32028|31734|29342|21593|11944|9043|\n",
      "|  18|3314|4383| 7332| 8440|19013|22257|25347|25571|22663|16048| 8319|6396|\n",
      "|  19|2147|2556| 4556| 5487|14104|17638|19146|18937|15996| 9865| 5228|4046|\n",
      "+----+----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tripsPerMonthAndHourDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1c768c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(tripsPerMonthAndHourDF.columns) == 13)\n",
    "assert(tripsPerMonthAndHourDF.columns[0] == \"Hora\")\n",
    "assert(tripsPerMonthAndHourDF.columns[12] == \"Dic\")\n",
    "assert(tripsPerMonthAndHourDF.count() == 24)\n",
    "todasHoras = tripsPerMonthAndHourDF.collect()\n",
    "assert((todasHoras[0][\"Hora\"] == 0) & (todasHoras[0][\"Dic\"]==782))\n",
    "assert((todasHoras[23][\"Hora\"] == 23) & (todasHoras[23][\"Dic\"]==1208))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15889d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJERCICIO 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a686a49",
   "metadata": {},
   "source": [
    "Partiendo de tripsTorontoTimesDF definido anteriormente, añadir las siguientes columnas:\n",
    "\n",
    "Primero, tres columnas adicionales llamadas dur_media, dur_min, dur_max que contengan, respectivamente, la duración media, mínima y máxima de los viajes que parten de esa misma estación de origen (from_station_id) a esa misma hora y en ese mismo mes del año. Es decir, queremos una columna extra para que podamos tener, junto a cada viaje, información agregada de los viajes similares, entendidos como aquellos que salieron a la misma hora de la misma estación. No se debe utilizar JOIN sino solo funciones de ventana.\n",
    "A continuación, otra columna adicional diff_dur_porc que contenga la diferencia, medida en porcentaje, entre la duración del viaje y la duración media de los viajes similares calculada en el apartado anterior. Dicha diferencia debe calcularse como la resta de la duración del viaje menos la duración media, dividida entre la duración media y multiplicada por 100. El resultado debe obtenerse aplicando operaciones aritméticas con columnas existentes, sin utilizar when.\n",
    "El DF resultante con las 4 columnas nuevas que hemos añadido debe almacenarse en la variable tripsTorontoExtraInfoDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9ae0c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window\n",
    "windowHoraMesEstacion =Window().partitionBy(\"from_station_id\",\"Hora\", \"Mes\")\n",
    "tripsTorontoExtraInfoDF = tripsTorontoTimesDF.withColumn(\"dur_media\", F.avg(\"trip_duration_seconds\").over(windowHoraMesEstacion))\\\n",
    "                                             .withColumn(\"dur_min\", F.min(\"trip_duration_seconds\").over(windowHoraMesEstacion))\\\n",
    "                                             .withColumn(\"dur_max\", F.max(\"trip_duration_seconds\").over(windowHoraMesEstacion))\\\n",
    "                                             .withColumn(\"diff_dur_porc\",((F.col(\"trip_duration_seconds\") - F.col(\"dur_media\"))\\\n",
    "                                                                          /(F.col(\"dur_media\")))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e771dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = tripsTorontoExtraInfoDF.where(\"trip_id = '2970611'\").head()\n",
    "assert(r.dur_media - 783.366666667 < 0.001)\n",
    "assert(r.diff_dur_porc - 44.24918088591975 < 0.001)\n",
    "assert(r.dur_min == 167)\n",
    "assert(r.dur_max == 2333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7562a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ejercicio 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0682a964",
   "metadata": {},
   "source": [
    "Partiendo de tripsTorontoTimesDF, crear un grafo llamado bikeGraph utilizando como identificador de los vértices los identificadores de las estaciones. Construye primero un DF con todos los identificadores de las estaciones, simplemente seleccionando from_station_id, renombrando adecuadamente el nombre de columna. Puedes almacenar este DF en la variable verticesDF. También tendrás que renombrar las columnas from_station_id y to_station_id en el DF de aristas, para el que además deberás seleccionar solo dichas columnas y quitar las filas repetidas ya que solo necesitamos considerar una vez cada ruta (cada pareja de estación inicial y final). Puedes almacenar el resultado del renombramiento y la eliminación de repetidos en la variable edgesDF.\n",
    "Una vez creado, aplica el algoritmo pageRank pasando como único parámetro maxIter = 5. El algoritmo puede llegar a emplear más de 10 minutos.\n",
    "Almacena el grafo devuelto por dicha función en la variable pageRankGraph, recupera el DF de sus vértices, ordénalo descendentemente en base a la columna pagerank y almacena el resultado en la variable sortedPageRankGraphVerticesDF\n",
    "Obtén el identificador de la estación más relevante (con mayor valor de la métrica pageRank, que ocupará la primera fila tras la ordenación), y almacena dicho identificador en la variable id_mas_relevante.\n",
    "Crea un nuevo DF de una sola fila y tres columnas llamadas dur_media, dur_min y dur_max con la duración media, mínima y máxima de los viajes de tripsTorontoTimesDF que empiezan en dicha estación (sin tener en cuenta distinción de horas o meses). No debe usarse la función withColumn sino crear las columnas al vuelo con select. Debe quedar almacenado en la variable durEstMasRelevantesDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "259a250b",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o208.createGraph.\n: java.lang.NoSuchMethodError: 'scala.collection.mutable.ArrayOps scala.Predef$.refArrayOps(java.lang.Object[])'\r\n\tat org.graphframes.GraphFrame$.apply(GraphFrame.scala:676)\r\n\tat org.graphframes.GraphFramePythonAPI.createGraph(GraphFramePythonAPI.scala:10)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:564)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.base/java.lang.Thread.run(Thread.java:832)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-610c98755c11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m                              .withColumnRenamed(\"to_station_id\",\"dst\"))\\\n\u001b[0;32m      7\u001b[0m           \u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"src\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dst\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistinct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mbikeGraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGraphFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverticesDF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medgesDF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mpageRankGraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbikeGraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpageRank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaxIter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0msortedPageRankGraphVerticesDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpageRankGraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morderBy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pageRank\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\spark-a1fd7609-f5fe-4d8b-8254-0364c94bbd67\\userFiles-f47b45e5-ac3b-44a8-9004-ec5decea9f01\\graphframes_graphframes-0.8.0-spark2.4-s_2.11.jar\\graphframes\\graphframe.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, v, e)\u001b[0m\n\u001b[0;32m     87\u001b[0m                 .format(self.DST, \",\".join(e.columns)))\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm_gf_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreateGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                 raise Py4JJavaError(\n\u001b[0m\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o208.createGraph.\n: java.lang.NoSuchMethodError: 'scala.collection.mutable.ArrayOps scala.Predef$.refArrayOps(java.lang.Object[])'\r\n\tat org.graphframes.GraphFrame$.apply(GraphFrame.scala:676)\r\n\tat org.graphframes.GraphFramePythonAPI.createGraph(GraphFramePythonAPI.scala:10)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:564)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.base/java.lang.Thread.run(Thread.java:832)\r\n"
     ]
    }
   ],
   "source": [
    "from graphframes import *\n",
    "from graphframes import GraphFrame\n",
    "spark.sparkContext.setCheckpointDir(\"/tmp\")\n",
    "verticesDF = tripsTorontoTimesDF.select(F.col(\"from_station_id\").alias(\"id\")).distinct()\n",
    "edgesDF = (tripsTorontoTimesDF.withColumnRenamed(\"from_station_id\",\"src\")\\\n",
    "                             .withColumnRenamed(\"to_station_id\",\"dst\"))\\\n",
    "          .select(\"src\", \"dst\").distinct()\n",
    "bikeGraph = GraphFrame(verticesDF, edgesDF)\n",
    "pageRankGraph = bikeGraph.pageRank(maxIter=5)\n",
    "sortedPageRankGraphVerticesDF = pageRankGraph.select(\"id\").orderBy(col(\"pageRank\"), descending=True)\n",
    "id_mas_relevante = sortedPageRankGraphVerticesDF.select(\"id\").first()\n",
    "durEstMasRelevantesDF =  tripsTorontoTimesDF.select( F.avg(\"trip_duration_seconds\").alias(\"avg\"),\\\n",
    "                                                    F.min(\"trip_duration_seconds\").alias(\"dur_min\"),\\\n",
    "                                                    F.max(\"trip_duration_seconds\").alias(\"dur_max\"))\\\n",
    ".where(col(\"from_station_id\")==id_mas_relevante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03175688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from graphframes import GraphFrame\n",
    "\n",
    "spark.sparkContext.setCheckpointDir(\"/tmp\")\n",
    "verticesDF = tripsTorontoTimesDF.select(F.col(\"from_station_id\").alias(\"id\")).distinct().cache()\n",
    "edgesDF = tripsTorontoTimesDF.withColumnRenamed(\"from_station_id\", \"src\")\\\n",
    "                             .withColumnRenamed(\"to_station_id\", \"dst\")\\\n",
    "                             .select(\"src\", \"dst\")\\\n",
    "                             .distinct()\\\n",
    "                             .cache()\n",
    "bikeGraph = GraphFrame(verticesDF, edgesDF)\n",
    "pageRankGraph = bikeGraph.pageRank(maxIter=10)\n",
    "sortedPageRankGraphVerticesDF = pageRankGraph.vertices.orderBy(F.col(\"pagerank\").desc())\n",
    "id_mas_relevante = sortedPageRankGraphVerticesDF.select(\"id\").first()[0]\n",
    "durEstMasRelevantesDF = tripsTorontoTimesDF.where(F.col(\"from_station_id\") == id_mas_relevante)\\\n",
    "                            .select(F.max(F.col(\"trip_duration_seconds\")).alias(\"dur_max\"),\n",
    "                                    F.min(F.col(\"trip_duration_seconds\")).alias(\"dur_min\"),\n",
    "                                    F.mean(F.col(\"trip_duration_seconds\")).alias(\"dur_media\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f4bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(sortedPageRankGraphVerticesDF.head()[\"pagerank\"] - 1.4427 < 0.01)\n",
    "assert(durEstMasRelevantesDF.count() == 1)\n",
    "assert(len(durEstMasRelevantesDF.columns) == 3)\n",
    "rEstMasRelevantes = durEstMasRelevantesDF.head()\n",
    "assert(rEstMasRelevantes.dur_min == 61)\n",
    "assert(id_mas_relevante == 7060)\n",
    "assert(rEstMasRelevantes.dur_media - 747.6957692082626 < 0.001)\n",
    "assert(rEstMasRelevantes.dur_max == 35130)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
