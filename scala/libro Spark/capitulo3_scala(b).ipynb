{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17b5f38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://L2108020.bosonit.local:4041\n",
       "SparkContext available as 'sc' (version = 3.1.2, master = local[*], app id = local-1633337183746)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42d8f43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@fd8a856\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " val spark = SparkSession.builder.appName(\"MnMCount\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19d1395f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sfFireFile: String = C:/Users/laura.serrano/Desktop/big_data/spark/LearningSparkV2-master/LearningSparkV2-master/chapter2/py/src/data/mnm_dataset.csv\r\n",
       "fireDF: org.apache.spark.sql.DataFrame = [State: string, Color: string ... 1 more field]\r\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sfFireFile=\"C:/Users/laura.serrano/Desktop/big_data/spark/LearningSparkV2-master/LearningSparkV2-master/chapter2/py/src/data/mnm_dataset.csv\"\n",
    "val fireDF = spark.read.option(\"header\", \"true\")\n",
    " .csv(sfFireFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26d1217c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- State: string (nullable = true)\n",
      " |-- Color: string (nullable = true)\n",
      " |-- Count: string (nullable = true)\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "fireDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afaddfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "/*Guardar en formato JSON*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aff16db9",
   "metadata": {},
   "outputs": [
    {
     "ename": "org.apache.spark.sql.AnalysisException",
     "evalue": " path file:/C:/Users/laura.serrano/Desktop/big_data/spark/LearningSparkV2-master/LearningSparkV2-master/chapter3/mm_dataset(SCALA).json already exists.\r",
     "output_type": "error",
     "traceback": [
      "org.apache.spark.sql.AnalysisException: path file:/C:/Users/laura.serrano/Desktop/big_data/spark/LearningSparkV2-master/LearningSparkV2-master/chapter3/mm_dataset(SCALA).json already exists.\r",
      "  at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:122)\r",
      "  at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)\r",
      "  at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)\r",
      "  at org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)\r",
      "  at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\r",
      "  at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\r",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r",
      "  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\r",
      "  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\r",
      "  at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:132)\r",
      "  at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:131)\r",
      "  at org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:989)\r",
      "  at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\r",
      "  at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\r",
      "  at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\r",
      "  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\r",
      "  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r",
      "  at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:989)\r",
      "  at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:438)\r",
      "  at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:415)\r",
      "  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:293)\r",
      "  ... 37 elided\r",
      ""
     ]
    }
   ],
   "source": [
    "val json_path = \"C:/Users/laura.serrano/Desktop/big_data/spark/LearningSparkV2-master/LearningSparkV2-master/chapter3/mm_dataset(SCALA).json\"\n",
    "fireDF.write.format(\"json\").save(json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5454e796",
   "metadata": {},
   "outputs": [],
   "source": [
    "/*Guardar en formato CSV*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26356166",
   "metadata": {},
   "outputs": [],
   "source": [
    "val csv_path = \"C:/Users/laura.serrano/Desktop/big_data/spark/LearningSparkV2-master/LearningSparkV2-master/chapter3/mnm_count(1)(scala).csv\"\n",
    "fireDF.write.format(\"csv\").save(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd55f5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "/*Guardar en formato AVRO*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45a60faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avro_path: String = C:/Users/laura.serrano/Desktop/big_data/spark/LearningSparkV2-master/LearningSparkV2-master/chapter3/mnm_count(1)(SCALA).avro\r\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val avro_path = \"C:/Users/laura.serrano/Desktop/big_data/spark/LearningSparkV2-master/LearningSparkV2-master/chapter3/mnm_count(1)(SCALA).avro\"\n",
    "fireDF.write.format(\"avro\").save(avro_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "542c128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "/*Obtener el n√∫meor de particiones*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "323700b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res6: Int = 1\r\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fireDF.rdd.getNumPartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88e9a6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "/*gUARDAR ARCHIVO EN FORMATO CSV EN DOS PARTICIONES*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd6b99c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "csv_path: String = C:/Users/laura.serrano/Desktop/big_data/spark/LearningSparkV2-master/LearningSparkV2-master/chapter3/mnm_count(particion2)(scala).csv\r\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val csv_path = \"C:/Users/laura.serrano/Desktop/big_data/spark/LearningSparkV2-master/LearningSparkV2-master/chapter3/mnm_count(particion2)(scala).csv\"\n",
    "fireDF.repartition(2).write.format(\"csv\").save(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9004464b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "csv_path: String = C:/Users/laura.serrano/Desktop/big_data/spark/LearningSparkV2-master/LearningSparkV2-master/chapter3/mnm_count(particion3)(scala).csv\r\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val csv_path = \"C:/Users/laura.serrano/Desktop/big_data/spark/LearningSparkV2-master/LearningSparkV2-master/chapter3/mnm_count(particion3)(scala).csv\"\n",
    "fireDF.repartition(3).write.format(\"csv\").save(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4828adf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
